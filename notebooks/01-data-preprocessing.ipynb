{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from etna.datasets.tsdataset import TSDataset\n",
    "from etna.transforms import MedianOutliersTransform\n",
    "from etna.transforms import TimeSeriesImputerTransform\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path(\"__file__\").resolve().parents[1]\n",
    "\n",
    "DATA_DPATH = PROJECT_ROOT / \"data\"\n",
    "assert DATA_DPATH.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fpath = DATA_DPATH / \"preprocessed_data\" / \"resampled_product.csv\"\n",
    "\n",
    "df = pd.read_csv(df_fpath, index_col=0)\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df = df.rename(columns={\"quantity\": \"target\"})\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = date(2020, 2, 29)\n",
    "\n",
    "train_df = df[df[\"timestamp\"].dt.date <= split_date]\n",
    "test_df = df[df[\"timestamp\"].dt.date > split_date]\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"segment\"] = 10\n",
    "ts_train_df = TSDataset(train_df, freq=\"D\")\n",
    "\n",
    "# --- Outlier Processing --- #\n",
    "outliers_remover = MedianOutliersTransform(in_column=\"target\", window_size=30)\n",
    "ts_train_df.fit_transform([outliers_remover])\n",
    "\n",
    "print(\"number of series with outliers:\", len(outliers_remover.outliers_timestamps))\n",
    "print(\"total number of outliers:\", sum([len(values) for values in outliers_remover.outliers_timestamps.values()]))\n",
    "\n",
    "# --- Null Filling --- #\n",
    "imputer = TimeSeriesImputerTransform(in_column=\"target\", strategy=\"running_mean\", window=30)\n",
    "ts_train_df.fit_transform([imputer])\n",
    "\n",
    "preprocessed_train_df = ts_train_df.to_pandas(flatten=True)\n",
    "preprocessed_train_df = preprocessed_train_df.dropna(subset=[\"target\"])\n",
    "preprocessed_train_df = preprocessed_train_df.drop(columns=[\"segment\"])\n",
    "\n",
    "preprocessed_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for correct null filling - must be 1 days for every train_df\n",
    "df_check = preprocessed_train_df.copy()\n",
    "df_check[\"date_tt_shifted\"] = df_check[\"timestamp\"].shift()\n",
    "df_check = df_check[~df_check[\"date_tt_shifted\"].isna()]\n",
    "print((df_check[\"timestamp\"] - df_check[\"date_tt_shifted\"]).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dpath = DATA_DPATH / \"datasets\"\n",
    "dataset_dpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "preprocessed_train_df.to_csv(dataset_dpath / \"train.csv\")\n",
    "test_df.to_csv(dataset_dpath / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
